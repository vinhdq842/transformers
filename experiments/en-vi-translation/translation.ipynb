{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from modules.utils import create_pad_mask, create_subsequent_mask, BPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mt_eng_vietnamese (/media/4TDISK/vinhdq/transformers/experiments/en-vi-translation/datasets/mt_eng_vietnamese/iwslt2015-vi-en/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85050a15c59b480faf48e480ed487088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /media/4TDISK/vinhdq/transformers/experiments/en-vi-translation/datasets/mt_eng_vietnamese/iwslt2015-vi-en/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71/cache-fc7fd65423ac5fc0.arrow\n",
      "Loading cached processed dataset at /media/4TDISK/vinhdq/transformers/experiments/en-vi-translation/datasets/mt_eng_vietnamese/iwslt2015-vi-en/1.0.0/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71/cache-42424f4ef5424984.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3418e8451df04593900bfb3f52c96f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/133318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dfabebbdc345c4b3bfa0ebbe0f24ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vi_en_dataset = load_dataset(\n",
    "    \"mt_eng_vietnamese\", \"iwslt2015-vi-en\", cache_dir=\"datasets\"\n",
    ")\n",
    "\n",
    "\n",
    "def unescape(batch):\n",
    "    batch[\"vi\"] = html.unescape(batch[\"translation\"][\"vi\"])\n",
    "    batch[\"en\"] = html.unescape(batch[\"translation\"][\"en\"])\n",
    "    return batch\n",
    "\n",
    "\n",
    "del vi_en_dataset[\"validation\"]\n",
    "vi_en_dataset = vi_en_dataset.map(unescape, remove_columns=\"translation\")\n",
    "vi_en_dataset.save_to_disk(\"datasets/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "vi_en_dataset = load_from_disk(\"datasets/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /media/4TDISK/vinhdq/transformers/experiments/en-vi-translation/datasets/processed/train/cache-196c82b5e6a7bca1.arrow\n",
      "Loading cached processed dataset at /media/4TDISK/vinhdq/transformers/experiments/en-vi-translation/datasets/processed/test/cache-63dd10933077689b.arrow\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean(batch):\n",
    "    en = batch[\"en\"].lower()\n",
    "    vi = batch[\"vi\"].lower()\n",
    "\n",
    "    en = re.sub(r\"\\s+\", \" \", en).strip()\n",
    "#    en = re.sub(r\"([0-9,.]{2,})(?![a-z-])\", \"\", en)\n",
    "#    en = re.sub(r\"[-.]{2,}[0-9.]*\", \"\", en)\n",
    "    en = \" \".join(list(filter(lambda x: len(x), en.split())))\n",
    "    batch[\"en\"] = en\n",
    "\n",
    "    vi = re.sub(r\"\\s+\", \" \", vi).strip()\n",
    "#    vi = re.sub(r\"([0-9,.]{2,})(?![a-z-])\", \"\", vi)\n",
    "#    vi = re.sub(r\"[-.]{2,}[0-9.]*\", \"\", vi)\n",
    "    vi = \" \".join(list(filter(lambda x: len(x), vi.split())))\n",
    "    batch[\"vi\"] = vi\n",
    "    return batch\n",
    "\n",
    "\n",
    "vi_en_dataset = vi_en_dataset.map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BPETokenizer()\n",
    "tokenizer.load_state_dict(torch.load(\"tokenizer.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import pad\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, src, tgt):\n",
    "        self.src = src\n",
    "        self.tgt = tgt\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.src[index],\n",
    "            len(self.src[index]),\n",
    "            self.tgt[index],\n",
    "            len(self.tgt[index]),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    @classmethod\n",
    "    def pad(cls, inputs, tgt=False):\n",
    "        def pad_data(x, length):\n",
    "            x_padded = pad(x, (0, length - x.shape[0]), mode=\"constant\", value=tokenizer._st2i[tokenizer.pad])\n",
    "            return x_padded\n",
    "\n",
    "        max_len = max((len(x) for x in inputs)) + tgt\n",
    "        padded = torch.stack([pad_data(torch.LongTensor(x), max_len) for x in inputs])\n",
    "\n",
    "        return padded\n",
    "\n",
    "    @classmethod\n",
    "    def collate_fn(cls, batch):\n",
    "        src = []\n",
    "        src_lens = []\n",
    "        tgt = []\n",
    "        tgt_lens = []\n",
    "        for s, sl, t, tl in batch:\n",
    "            src.append(s)\n",
    "            src_lens.append(sl)\n",
    "            tgt.append(t)\n",
    "            tgt_lens.append(tl)\n",
    "        return (\n",
    "            cls.pad(src),\n",
    "            torch.LongTensor(src_lens),\n",
    "            cls.pad(tgt, tgt=True),\n",
    "            torch.LongTensor(tgt_lens),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2idx(batch):\n",
    "    batch[\"ids_vi\"] = (\n",
    "        [tokenizer._st2i[tokenizer.sos]] + tokenizer(batch[\"vi\"]) + [tokenizer._st2i[tokenizer.eos]]\n",
    "    )\n",
    "    batch[\"ids_en\"] = tokenizer(batch[\"en\"])\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05fff45711b498db5fdcd4ade7742fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/133318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632eedfe39234caea761adba0d4f2f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vi_en_ids = vi_en_dataset.map(\n",
    "    token2idx, remove_columns=vi_en_dataset.column_names[\"train\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801e6a4b48694b079b604964ea2f4db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/133318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2e21e6c1754b19892c3226180a089e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vi_en_ids.save_to_disk(\"datasets/processed_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa30ddd2fcd41e8a0ce827e8652021a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/133318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0bb99c2d194edd8d365bc0fe674be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vi_en_ids = vi_en_ids.filter(\n",
    "    lambda batch: 2 < len(batch[\"ids_vi\"]) <= max_length\n",
    "    and 1 <= len(batch[\"ids_en\"]) <= max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ids_vi', 'ids_en'],\n",
       "        num_rows: 133137\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ids_vi', 'ids_en'],\n",
       "        num_rows: 1268\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_en_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', ' can', ' mimic', ' what', ' you', ' can', ' see', ' .']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(vi_en_ids[\"train\"][\"ids_en\"][56]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = vi_en_ids[\"train\"].train_test_split(test_size=0.01).values()\n",
    "vi_en_ids.update({\"train\": train, \"val\": val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74694159047c4fa0bc44107f973efbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/131805 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1023bc66d3c47e2874df0e49fcf88f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4391adbfbb8949c888fbbc7d7709610c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vi_en_ids.save_to_disk(\"datasets/processed_ids_splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "train_dl = DataLoader(\n",
    "    TextDataset(vi_en_ids[\"train\"][\"ids_en\"], vi_en_ids[\"train\"][\"ids_vi\"]),\n",
    "    batch_size= 2* batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    collate_fn=TextDataset.collate_fn,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    TextDataset(vi_en_ids[\"val\"][\"ids_en\"], vi_en_ids[\"val\"][\"ids_vi\"]),\n",
    "    batch_size=2 * batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    collate_fn=TextDataset.collate_fn,\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    TextDataset(vi_en_ids[\"test\"][\"ids_en\"], vi_en_ids[\"test\"][\"ids_vi\"]),\n",
    "    batch_size=2 * batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    collate_fn=TextDataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def bleu_score(candidates, references):\n",
    "    bleu = 0\n",
    "\n",
    "    def one(candidate, reference):\n",
    "        can = Counter(candidate)\n",
    "        ref = Counter(reference)\n",
    "        overlap = 0\n",
    "        for c in can:\n",
    "            overlap += min(can.get(c, 0), ref.get(c, 0))\n",
    "\n",
    "        return (\n",
    "            min(1, np.exp(1 - len(reference) / len(candidate)))\n",
    "            * overlap\n",
    "            / sum(can.values())\n",
    "        )\n",
    "\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        if not isinstance(candidate, list) or not isinstance(reference, list):\n",
    "            candidate, reference = candidate.tolist(), reference.tolist()\n",
    "            if tokenizer._st2i[tokenizer.pad] in candidate:\n",
    "                candidate = candidate[:candidate.index(tokenizer._st2i[tokenizer.pad])]\n",
    "            if tokenizer._st2i[tokenizer.pad] in reference:\n",
    "                reference = reference[:reference.index(tokenizer._st2i[tokenizer.pad])]\n",
    "        bleu += one(candidate, reference)\n",
    "\n",
    "    return bleu / len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3274923012311928"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score([[1,2,3,44,0],[423,223,33,21,13]],[[32,2,1,4,6,3],[33,12,3,12,3,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 5,973,248 parameters.\n",
      "Trainable: 5,973,248 parameters.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from models.transformer import Transformer\n",
    "from modules.utils import count_params\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "n_heads = 4\n",
    "n_blocks = 4\n",
    "d_model = 128\n",
    "d_k = d_v = d_model // n_heads\n",
    "d_ff = 4 * d_model\n",
    "p_drop = 0.1\n",
    "\n",
    "model = Transformer(\n",
    "    vocab_size, n_heads, max_length, n_blocks, d_model, d_ff, d_k, d_v, p_drop\n",
    ").to(device)\n",
    "count_params(model)\n",
    "optimizer = Adam(model.parameters(), lr=0.0002, betas=(0.98, 0.99))\n",
    "scheduler = ExponentialLR(optimizer, 0.99**0.125)\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1,ignore_index=tokenizer._st2i[tokenizer.pad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011108996538242306"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.exp(-4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-6,-0.6,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "lrs = []\n",
    "i = 0\n",
    "while i < len(lre):\n",
    "    for src, src_lens, tgt, tgt_lens in val_dl:\n",
    "        src, src_lens, tgt, tgt_lens = (\n",
    "            src.to(device),\n",
    "            src_lens.to(device),\n",
    "            tgt.to(device),\n",
    "            tgt_lens.to(device),\n",
    "        )\n",
    "\n",
    "        src_mask = create_pad_mask(src_lens)\n",
    "        tgt_0 = tgt[:, :-1]\n",
    "        tgt_0_mask = create_subsequent_mask(tgt_lens, pad_mask=create_pad_mask(tgt_lens))\n",
    "        tgt_1 = tgt[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        optimizer.param_groups[0]['lr'] = math.exp(lre[i])\n",
    "        logits = model(src, src_mask, tgt_0, tgt_0_mask)\n",
    "        loss = loss_fn(logits.view(-1, vocab_size), tgt_1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        lrs.append(lre[i])\n",
    "        i += 1\n",
    "        if i == len(lre):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8955683940>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lrs,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "\n",
    "def train_and_eval(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    scheduler,\n",
    "    epochs,\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    early_stopping=10,\n",
    "    model_name=\"sample_model\",\n",
    "):\n",
    "    p_bar = tqdm(total=len(train_dl))\n",
    "\n",
    "    best_val_loss = 25042001\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_bleu = 0\n",
    "        val_loss = 0\n",
    "        val_bleu = 0\n",
    "\n",
    "        model.train()\n",
    "        for src, src_lens, tgt, tgt_lens in train_dl:\n",
    "            src, src_lens, tgt, tgt_lens = (\n",
    "                src.to(device),\n",
    "                src_lens.to(device),\n",
    "                tgt.to(device),\n",
    "                tgt_lens.to(device),\n",
    "            )\n",
    "\n",
    "            src_mask = create_pad_mask(src_lens)\n",
    "            tgt_0 = tgt[:, :-1]\n",
    "            tgt_0_mask = create_subsequent_mask(tgt_lens, pad_mask=create_pad_mask(tgt_lens))\n",
    "            tgt_1 = tgt[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            logits = model(src, src_mask, tgt_0, tgt_0_mask)\n",
    "            loss = loss_fn(logits.view(-1, vocab_size), tgt_1)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_bleu += bleu_score(logits.argmax(-1), tgt[:, 1:])\n",
    "\n",
    "            p_bar.update(1)\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        print(''.join(tokenizer.decode(decode(model,tokenizer,'a single female will lay about up to eggs at a time , up to about in her lifetime .')[0].tolist())))\n",
    "        with torch.inference_mode():\n",
    "            for src, src_lens, tgt, tgt_lens in val_dl:\n",
    "                src, src_lens, tgt, tgt_lens = (\n",
    "                    src.to(device),\n",
    "                    src_lens.to(device),\n",
    "                    tgt.to(device),\n",
    "                    tgt_lens.to(device),\n",
    "                )\n",
    "\n",
    "                src_mask = create_pad_mask(src_lens)\n",
    "                tgt_0 = tgt[:, :-1]\n",
    "                tgt_0_mask = create_subsequent_mask(tgt_lens, pad_mask=create_pad_mask(tgt_lens))\n",
    "                tgt_1 = tgt[:, 1:].contiguous().view(-1)\n",
    "\n",
    "                logits = model(src, src_mask, tgt_0, tgt_0_mask)\n",
    "                loss = loss_fn(logits.view(-1, vocab_size), tgt_1)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_bleu += bleu_score(logits.argmax(-1), tgt[:, 1:])\n",
    "\n",
    "        train_loss /= len(train_dl)\n",
    "        val_loss /= len(val_dl)\n",
    "        train_bleu = train_bleu / len(train_dl)\n",
    "        val_bleu = val_bleu / len(val_dl)\n",
    "\n",
    "        if val_loss > best_val_loss:\n",
    "            patience += 1\n",
    "        else:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"checkpoints/{model_name}.pth\",\n",
    "            )\n",
    "            patience = 0\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}:\\n Train loss: {train_loss:.6f} - Train bleu: {train_bleu:.6f}\\n Val loss: {val_loss:.6f} - Val bleu: {val_bleu:.6f}\"\n",
    "        )\n",
    "\n",
    "        if patience >= early_stopping:\n",
    "            print(\n",
    "                f\"Stopped since val loss has not improved in the last {early_stopping} epochs...\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "        p_bar.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1664ec462e894fd2a37c90d52450fad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>như chiếc ký triệu nơi mà chúng ta biết rằng bạn trang gì đối với nhau , và bạn đi lên chụp sau một hành động về một hành động\n",
      "Epoch 1:\n",
      " Train loss: 3.820629 - Train bleu: 0.200767\n",
      " Val loss: 2.931866 - Val bleu: 0.244299\n",
      "<sos> bàn functionality hình thì chúng ta là một hành động tài nguyên thể hiện ra cải cách gì phát minh là một hành động về một hành động tài nguyên\n",
      "Epoch 2:\n",
      " Train loss: 3.793968 - Train bleu: 0.202199\n",
      " Val loss: 2.927662 - Val bleu: 0.243860\n",
      "<sos> mỳ .<eos>\n",
      "Epoch 3:\n",
      " Train loss: 3.773126 - Train bleu: 0.204438\n",
      " Val loss: 2.904943 - Val bleu: 0.246178\n",
      "<sos> mỳ về con người chủ chủ chủ chủ chủ chủ chủ chủ chủ chủ chủ nghĩa chia sẻ và thời gian tài mau chủ nghĩa là bạn về con karl\n",
      "Epoch 4:\n",
      " Train loss: 3.763139 - Train bleu: 0.204368\n",
      " Val loss: 2.887444 - Val bleu: 0.246854\n",
      "<sos>như karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl sức khoẻ về nơi mà bao giờ là một nơi màs.\n",
      "Epoch 5:\n",
      " Train loss: 3.754018 - Train bleu: 0.203864\n",
      " Val loss: 2.864369 - Val bleu: 0.249981\n",
      "<sos>như karl karl karl karl karl karl karl karl karl karl karl karl karl của mỳ thì chúng ta hay độ exhi thức bắt đầu ra một hành động tài\n",
      "Epoch 6:\n",
      " Train loss: 3.735437 - Train bleu: 0.205067\n",
      " Val loss: 2.868720 - Val bleu: 0.249473\n",
      "<sos> bàn<eos>\n",
      "Epoch 7:\n",
      " Train loss: 3.726676 - Train bleu: 0.205229\n",
      " Val loss: 2.846477 - Val bleu: 0.250468\n",
      "<sos>như sao gì sau đó là một hành động tài m rằng là một hành động tài m m m m m m m m m m m m m\n",
      "Epoch 8:\n",
      " Train loss: 3.698561 - Train bleu: 0.207479\n",
      " Val loss: 2.820381 - Val bleu: 0.250864\n",
      "<sos> mỳ về con người và both both both both both both both both đang gì chuyên thuật ủng hộ sao gì .<eos>\n",
      "Epoch 9:\n",
      " Train loss: 3.680792 - Train bleu: 0.208304\n",
      " Val loss: 2.792071 - Val bleu: 0.255058\n",
      "<sos> mỳ về con người và both both là là là một hành động tài liệu và tật về con người gì chúng ta hiểu về một hành động về một\n",
      "Epoch 10:\n",
      " Train loss: 3.652004 - Train bleu: 0.209924\n",
      " Val loss: 2.778934 - Val bleu: 0.255715\n",
      "<sos> bàn<eos>\n",
      "Epoch 11:\n",
      " Train loss: 3.630643 - Train bleu: 0.211402\n",
      " Val loss: 2.757499 - Val bleu: 0.256185\n",
      "<sos> bàn<eos>\n",
      "Epoch 12:\n",
      " Train loss: 3.628115 - Train bleu: 0.211717\n",
      " Val loss: 2.743118 - Val bleu: 0.258053\n",
      "<sos> mỳ .<eos>\n",
      "Epoch 13:\n",
      " Train loss: 3.615147 - Train bleu: 0.211235\n",
      " Val loss: 2.722032 - Val bleu: 0.259458\n",
      "<sos> mỳ .<eos>\n",
      "Epoch 14:\n",
      " Train loss: 3.600086 - Train bleu: 0.212665\n",
      " Val loss: 2.704761 - Val bleu: 0.259633\n",
      "<sos> bàn xuất phát hiện ra một hành động về con người và sau đó , và thời gian bị văn hoá nghiên cứu mới về một lý thuyết mạng kỹ\n",
      "Epoch 15:\n",
      " Train loss: 3.581614 - Train bleu: 0.212992\n",
      " Val loss: 2.692599 - Val bleu: 0.260847\n",
      "<sos> bàn<eos>\n",
      "Epoch 16:\n",
      " Train loss: 3.556114 - Train bleu: 0.213407\n",
      " Val loss: 2.687024 - Val bleu: 0.259902\n",
      "<sos> bàn<eos>\n",
      "Epoch 17:\n",
      " Train loss: 3.551384 - Train bleu: 0.214758\n",
      " Val loss: 2.664647 - Val bleu: 0.262011\n",
      "<sos> bàn<eos>\n",
      "Epoch 18:\n",
      " Train loss: 3.523008 - Train bleu: 0.216190\n",
      " Val loss: 2.654254 - Val bleu: 0.262345\n",
      "<sos> bàn<eos>\n",
      "Epoch 19:\n",
      " Train loss: 3.508374 - Train bleu: 0.216317\n",
      " Val loss: 2.628790 - Val bleu: 0.264665\n",
      "<sos> bàn<eos>\n",
      "Epoch 20:\n",
      " Train loss: 3.506009 - Train bleu: 0.215024\n",
      " Val loss: 2.615754 - Val bleu: 0.265986\n",
      "<sos> bàn<eos>\n",
      "Epoch 21:\n",
      " Train loss: 3.501683 - Train bleu: 0.216313\n",
      " Val loss: 2.613756 - Val bleu: 0.265240\n",
      "<sos> bàn<eos>\n",
      "Epoch 22:\n",
      " Train loss: 3.484982 - Train bleu: 0.216870\n",
      " Val loss: 2.602837 - Val bleu: 0.266727\n",
      "<sos> bàn<eos>\n",
      "Epoch 23:\n",
      " Train loss: 3.454999 - Train bleu: 0.218803\n",
      " Val loss: 2.577003 - Val bleu: 0.268756\n",
      "<sos> bàn về văn hoá nó gặp kết quả ra một hành động tài m m m về một hành động tài m rằng bạn về một hành động về con\n",
      "Epoch 24:\n",
      " Train loss: 3.446759 - Train bleu: 0.217959\n",
      " Val loss: 2.557974 - Val bleu: 0.269639\n",
      "<sos> bàn về con người là một hành động về con người và sau khi phát hiện điều gì sau khi kết nối sau quan trọng chủ nghĩa là một hành\n",
      "Epoch 25:\n",
      " Train loss: 3.432271 - Train bleu: 0.219793\n",
      " Val loss: 2.565086 - Val bleu: 0.266267\n",
      "<sos> tháng .<eos>\n",
      "Epoch 26:\n",
      " Train loss: 3.408926 - Train bleu: 0.220975\n",
      " Val loss: 2.535992 - Val bleu: 0.270549\n",
      "<sos> bàn quay thời gian để bose hiện cạnh kết quả ra một hành động tài m m m ràng về con người và bạn sẽ thư lần nữa chủ nghĩa\n",
      "Epoch 27:\n",
      " Train loss: 3.400433 - Train bleu: 0.219375\n",
      " Val loss: 2.518763 - Val bleu: 0.272678\n",
      "<sos> bàn<eos>\n",
      "Epoch 28:\n",
      " Train loss: 3.371732 - Train bleu: 0.222682\n",
      " Val loss: 2.503332 - Val bleu: 0.273127\n",
      "<sos> bàn<eos>\n",
      "Epoch 29:\n",
      " Train loss: 3.362559 - Train bleu: 0.223376\n",
      " Val loss: 2.495000 - Val bleu: 0.274521\n",
      "<sos> bàn<eos>\n",
      "Epoch 30:\n",
      " Train loss: 3.353985 - Train bleu: 0.222276\n",
      " Val loss: 2.469680 - Val bleu: 0.275981\n",
      "<sos> tháng bởi hiện chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên khiến ta và bạn\n",
      "Epoch 31:\n",
      " Train loss: 3.333091 - Train bleu: 0.224814\n",
      " Val loss: 2.465512 - Val bleu: 0.275557\n",
      "<sos> tháng bởi hiện chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên chuyên khiến ta và bạn về một hành động sách ràng về một hành động sách\n",
      "Epoch 32:\n",
      " Train loss: 3.315460 - Train bleu: 0.227074\n",
      " Val loss: 2.447367 - Val bleu: 0.277611\n",
      "<sos> bàn<eos>\n",
      "Epoch 33:\n",
      " Train loss: 3.303684 - Train bleu: 0.225689\n",
      " Val loss: 2.438759 - Val bleu: 0.277830\n",
      "<sos> bàn<eos>\n",
      "Epoch 34:\n",
      " Train loss: 3.283638 - Train bleu: 0.226810\n",
      " Val loss: 2.421235 - Val bleu: 0.279375\n",
      "<sos> tháng bởi hiện chuyên chuyên chuyên chuyên gia tài liệu và chúng ta đã trai và lý thuyết tập trung cư gặp trợ và bạn về một lý do về\n",
      "Epoch 35:\n",
      " Train loss: 3.274755 - Train bleu: 0.227945\n",
      " Val loss: 2.421229 - Val bleu: 0.278924\n",
      "<sos> nghĩ rằng<eos>\n",
      "Epoch 36:\n",
      " Train loss: 3.265947 - Train bleu: 0.228169\n",
      " Val loss: 2.402347 - Val bleu: 0.280617\n",
      "<sos> tháng bởi hiện sức về một hành động về chuyên gia đình gì chuyên gia tài khó khó khó khăn .<eos>\n",
      "Epoch 37:\n",
      " Train loss: 3.241940 - Train bleu: 0.227957\n",
      " Val loss: 2.401136 - Val bleu: 0.280224\n",
      "<sos> mỳ về con người và vị nơi nơi nơi mà thời giancc thống kê kê xung quanh<eos>\n",
      "Epoch 38:\n",
      " Train loss: 3.236167 - Train bleu: 0.229683\n",
      " Val loss: 2.387982 - Val bleu: 0.281074\n",
      "<sos> mỳ về con người và vị nơi nơi nơi nơi mà nó đảo đố tay tay karl karl karl karl thời gianc thống kê trở thành một hành động\n",
      "Epoch 39:\n",
      " Train loss: 3.217192 - Train bleu: 0.229602\n",
      " Val loss: 2.369978 - Val bleu: 0.282223\n",
      "<sos> mỳ về nơi đuổi thuật nhóm đảo đệm thuật thuật ủng hộ vô nghĩa là một khó khó khó khăn nơi mà<eos>\n",
      "Epoch 40:\n",
      " Train loss: 3.190493 - Train bleu: 0.230783\n",
      " Val loss: 2.368801 - Val bleu: 0.281839\n",
      "<sos> mỳ về con người và vị nơi nơi mà<eos>\n",
      "Epoch 41:\n",
      " Train loss: 3.202735 - Train bleu: 0.230113\n",
      " Val loss: 2.346824 - Val bleu: 0.283838\n",
      "<sos> tháng bởi hiện sức về một hành động về con người và vị nơi mà thực hiện điều gì sau khi phát hiện điều hành động lực nhiều về điển\n",
      "Epoch 42:\n",
      " Train loss: 3.190365 - Train bleu: 0.231892\n",
      " Val loss: 2.337117 - Val bleu: 0.284801\n",
      "<sos> phim<eos>\n",
      "Epoch 43:\n",
      " Train loss: 3.172476 - Train bleu: 0.231875\n",
      " Val loss: 2.334115 - Val bleu: 0.284161\n",
      "<sos> mỳ về lý thuyết phục bởi vì một hành động lực nơi mà<eos>\n",
      "Epoch 44:\n",
      " Train loss: 3.158577 - Train bleu: 0.231918\n",
      " Val loss: 2.324415 - Val bleu: 0.284551\n",
      "<sos> xét hiểu và điều gì chúng ta bởi hành động lực là di chuyển hoá nghiên cứu nhiều động lực gia tài trợ bảo trợ trợ nguồn gặp trợ trực\n",
      "Epoch 45:\n",
      " Train loss: 3.149467 - Train bleu: 0.232889\n",
      " Val loss: 2.319206 - Val bleu: 0.285260\n",
      "<sos> xét hiểu và điều gì chúng ta chính tài nguyên thểcc về một hành động lực nơi mà nhiều về giả thuyết phục hồi trợ kéo dài và\n",
      "Epoch 46:\n",
      " Train loss: 3.133757 - Train bleu: 0.234565\n",
      " Val loss: 2.303801 - Val bleu: 0.286374\n",
      "<sos> xét hiểu và chúng ta có thể sát điều gì chúng ta là một hành động quan sát hồi và sau quan cư gì chúng ta là một khó khó\n",
      "Epoch 47:\n",
      " Train loss: 3.125819 - Train bleu: 0.234299\n",
      " Val loss: 2.295160 - Val bleu: 0.287331\n",
      "<sos> xét hiểu được là một nhiều động và chuyên gia nhiều động lực nơi mà chúng ta phim kê trợ trách nhiệm và sau một hành động do tại sao\n",
      "Epoch 48:\n",
      " Train loss: 3.119850 - Train bleu: 0.234993\n",
      " Val loss: 2.282541 - Val bleu: 0.288485\n",
      "<sos>chính như một đất .<eos>\n",
      "Epoch 49:\n",
      " Train loss: 3.094892 - Train bleu: 0.236889\n",
      " Val loss: 2.271246 - Val bleu: 0.289734\n",
      "<sos> nghĩ rằng hội karl cách tuyệt vời đã trai và điều đó là một hành động ra cải tất cả hành động lực lượng người gì chuyên động lực lượng\n",
      "Epoch 50:\n",
      " Train loss: 3.081736 - Train bleu: 0.236801\n",
      " Val loss: 2.271846 - Val bleu: 0.289384\n",
      "<sos> đảo khía cạnh cạnh thời điểm \"<eos>\n",
      "Epoch 51:\n",
      " Train loss: 3.066805 - Train bleu: 0.237911\n",
      " Val loss: 2.251451 - Val bleu: 0.291592\n",
      "<sos> xét hiểu rằng chúng ta điểm từng nhanh hơn và văn hoá hơn và bạn sẽ đời karl động lực gia đình lớn qua một khó khó khó khó khó\n",
      "Epoch 52:\n",
      " Train loss: 3.057287 - Train bleu: 0.238285\n",
      " Val loss: 2.239384 - Val bleu: 0.291946\n",
      "<sos> tháng bởi hiện sức về con space space space space space space space space space space space space space space space space space space space space space space space space\n",
      "Epoch 53:\n",
      " Train loss: 3.038445 - Train bleu: 0.239687\n",
      " Val loss: 2.238739 - Val bleu: 0.291638\n",
      "<sos> xét khủng nơi \" .<eos>\n",
      "Epoch 54:\n",
      " Train loss: 3.016610 - Train bleu: 0.240802\n",
      " Val loss: 2.235808 - Val bleu: 0.293051\n",
      "<sos> đảo khía cạnh 6 năm thành một khó sẽ ngươi về động thân và nguồn lượng nghiên cứu đầu tiên về động thân thể là một khó khó khó khó\n",
      "Epoch 55:\n",
      " Train loss: 3.005771 - Train bleu: 0.241004\n",
      " Val loss: 2.215236 - Val bleu: 0.294368\n",
      "<sos> đảo khía cạnh 6 năm thành một khó bạn bị ủng hộ sao và nhiều về nơi mà<eos>\n",
      "Epoch 56:\n",
      " Train loss: 2.993492 - Train bleu: 0.241932\n",
      " Val loss: 2.210444 - Val bleu: 0.294549\n",
      "<sos> đảo khía cạnh 6 linh<eos>\n",
      "Epoch 57:\n",
      " Train loss: 2.989393 - Train bleu: 0.242690\n",
      " Val loss: 2.197709 - Val bleu: 0.295484\n",
      "<sos>chính như chuyên gia hiện \"<eos>\n",
      "Epoch 58:\n",
      " Train loss: 2.962211 - Train bleu: 0.243964\n",
      " Val loss: 2.194362 - Val bleu: 0.295203\n",
      "<sos> xét hiểu được đồng được thể hiện đố sinh tập trung tâm trí là một khó khó khó khó khómw nghiên cứu đầu tập trung thực sự gì đối\n",
      "Epoch 59:\n",
      " Train loss: 2.956988 - Train bleu: 0.244203\n",
      " Val loss: 2.192114 - Val bleu: 0.295674\n",
      "<sos> xét hiểu ngột ngột anh và đồ và bạn bị trai và bạn về sự mỳ mỳ mỳ là bạn nghệ thuật nhóm đảo tình trạng khi kết quả ra\n",
      "Epoch 60:\n",
      " Train loss: 2.958501 - Train bleu: 0.243155\n",
      " Val loss: 2.189299 - Val bleu: 0.295285\n",
      "<sos> xét hiểu được đồng được lớn nhất là một điều gì chúng ta phim kê trợ<eos>\n",
      "Epoch 61:\n",
      " Train loss: 2.950587 - Train bleu: 0.244034\n",
      " Val loss: 2.176942 - Val bleu: 0.296499\n",
      "<sos> đảo khía cạnh 6 năm thành một khó đang gì chúng ta đang gì chuyên karl cách gì chuyên là bạn bị khó<eos>\n",
      "Epoch 62:\n",
      " Train loss: 2.939834 - Train bleu: 0.244691\n",
      " Val loss: 2.173921 - Val bleu: 0.296906\n",
      "<sos> đảo khía cạnh 6 năm thành một khó khó khó khó khó khó<eos>\n",
      "Epoch 63:\n",
      " Train loss: 2.936188 - Train bleu: 0.243491\n",
      " Val loss: 2.166712 - Val bleu: 0.296260\n",
      "<sos> xét hiểu rằng là là là một khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 64:\n",
      " Train loss: 2.923000 - Train bleu: 0.243077\n",
      " Val loss: 2.149050 - Val bleu: 0.297967\n",
      "<sos> xét hiểu như trang trang trang trang karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl karl ở\n",
      "Epoch 65:\n",
      " Train loss: 2.909044 - Train bleu: 0.246416\n",
      " Val loss: 2.155457 - Val bleu: 0.298079\n",
      "<sos> xét hiểu rằng chúng ta mới và nguồn rằng đồng được thể hiện cách chính là một khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 66:\n",
      " Train loss: 2.895569 - Train bleu: 0.246567\n",
      " Val loss: 2.145193 - Val bleu: 0.298908\n",
      "<sos> xét và sách và chúng ta ví dụ về vẻ sinh viên hậu hậu hậu .<eos>\n",
      "Epoch 67:\n",
      " Train loss: 2.892285 - Train bleu: 0.246297\n",
      " Val loss: 2.144677 - Val bleu: 0.299702\n",
      "<sos> xét hiểu và chúng ta về tám về một khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 68:\n",
      " Train loss: 2.877079 - Train bleu: 0.248019\n",
      " Val loss: 2.131840 - Val bleu: 0.299810\n",
      "<sos> xét chính dấu đồng được quan sát lên gặp bởi lí bất kỳ lâu karl sức khoẻ về một khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 69:\n",
      " Train loss: 2.866352 - Train bleu: 0.247782\n",
      " Val loss: 2.137941 - Val bleu: 0.299727\n",
      "<sos> xét chính sách đồng và buộc ngươi nối đó là là là một khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 70:\n",
      " Train loss: 2.860176 - Train bleu: 0.247717\n",
      " Val loss: 2.127316 - Val bleu: 0.300279\n",
      "<sos> xét chính sách đồng được kịp .<eos>\n",
      "Epoch 71:\n",
      " Train loss: 2.850999 - Train bleu: 0.249505\n",
      " Val loss: 2.120168 - Val bleu: 0.300998\n",
      "<sos> xét khủng như trang trang karl karl karl động ra tài nguyên và nhiều động thân và chúng ta về con space space space space space space space space space\n",
      "Epoch 72:\n",
      " Train loss: 2.834063 - Train bleu: 0.250522\n",
      " Val loss: 2.108722 - Val bleu: 0.301531\n",
      "<sos> xét chính sách đồng xu về sự gps .<eos>\n",
      "Epoch 73:\n",
      " Train loss: 2.814552 - Train bleu: 0.251697\n",
      " Val loss: 2.111683 - Val bleu: 0.301630\n",
      "<sos> xét và sách thuật buộc tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận tận\n",
      "Epoch 74:\n",
      " Train loss: 2.811749 - Train bleu: 0.251905\n",
      " Val loss: 2.104295 - Val bleu: 0.301940\n",
      "<sos> xét khủng nơi phiên bản năng lượng do tại sao hành động động ra cải ta động rằng sống ở suốt về động thân và nguồn miễn được sống được\n",
      "Epoch 75:\n",
      " Train loss: 2.808498 - Train bleu: 0.252302\n",
      " Val loss: 2.089560 - Val bleu: 0.302075\n",
      "<sos> đảo khía cạnh 6 năm thành một khó nào và bạn về con người do tại sao và nguồn về con người ví dụ về việc tuyệt vời lăn về\n",
      "Epoch 76:\n",
      " Train loss: 2.787896 - Train bleu: 0.254208\n",
      " Val loss: 2.101159 - Val bleu: 0.302044\n",
      "<sos> đảo khía cạnh 6 năm thành một khó đang gì chúng ta đã từng sau khi kết quả mà người và bạn về điển tay tay nghiên cứu đầu tiên\n",
      "Epoch 77:\n",
      " Train loss: 2.797534 - Train bleu: 0.252479\n",
      " Val loss: 2.089199 - Val bleu: 0.302797\n",
      "<sos> xét chính sách thuật buộc ngươi biệt thế năm 2008 kết quả ra một khó vậy ăn gấp là là đố đố sinh viên hậu động chia sẻ vào động\n",
      "Epoch 78:\n",
      " Train loss: 2.783643 - Train bleu: 0.252685\n",
      " Val loss: 2.085151 - Val bleu: 0.303099\n",
      "<sos> xét chính sách thuật gia đình 1 khoa học được chi được chi được là là là một đất<eos>\n",
      "Epoch 79:\n",
      " Train loss: 2.768265 - Train bleu: 0.254047\n",
      " Val loss: 2.083243 - Val bleu: 0.303455\n",
      "<sos> xét chính sách đồng và rosling sức tay tay tay tay tay tay tay tay bóng tối đã từng tưởng tưởng tưởng tưởng tưởng tưởng tưởng tưởng tưởng tưởng về\n",
      "Epoch 80:\n",
      " Train loss: 2.766354 - Train bleu: 0.254285\n",
      " Val loss: 2.084318 - Val bleu: 0.303848\n",
      "<sos> xét và sách phim la .<eos>\n",
      "Epoch 81:\n",
      " Train loss: 2.753328 - Train bleu: 0.254715\n",
      " Val loss: 2.083187 - Val bleu: 0.304117\n",
      "<sos> xét nói rằng động lực từng thực trợ và bao giờ là bản năng lượng bất bởi xuống từ both năm90 bằng cách khó khó khó khó khó khó\n",
      "Epoch 82:\n",
      " Train loss: 2.752415 - Train bleu: 0.254907\n",
      " Val loss: 2.065112 - Val bleu: 0.304372\n",
      "<sos> xét và văn hoá nó đã viết vĩ khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó nghiên cứu đầu tiên về một\n",
      "Epoch 83:\n",
      " Train loss: 2.744428 - Train bleu: 0.255736\n",
      " Val loss: 2.067266 - Val bleu: 0.304338\n",
      "<sos> xét chính dấu đồng được số đảo change khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 84:\n",
      " Train loss: 2.741778 - Train bleu: 0.255175\n",
      " Val loss: 2.071053 - Val bleu: 0.304881\n",
      "<sos> xét và văn hoá xa xử tròn mục thực sự tuyệt vời<eos>\n",
      "Epoch 85:\n",
      " Train loss: 2.736111 - Train bleu: 0.254566\n",
      " Val loss: 2.078857 - Val bleu: 0.303872\n",
      "<sos> xét và sách và chúng ta đã nghỉ hổ thuyết bởi vì mỳ .<eos>\n",
      "Epoch 86:\n",
      " Train loss: 2.725938 - Train bleu: 0.256171\n",
      " Val loss: 2.062373 - Val bleu: 0.304474\n",
      "<sos> xét và sách và vị này chủng khi đi vào chuyên gia đi vào từng vào đảo sinh viên và vị dậy mà thời gian dài về một khó khó\n",
      "Epoch 87:\n",
      " Train loss: 2.709647 - Train bleu: 0.257293\n",
      " Val loss: 2.063830 - Val bleu: 0.304796\n",
      "<sos> xét và sách thuật gia đình 1 con do tại sao hành động lực lượng qua sinh con do tại sao và nguồn phim vớisoon về một khó khó\n",
      "Epoch 88:\n",
      " Train loss: 2.704185 - Train bleu: 0.256889\n",
      " Val loss: 2.066339 - Val bleu: 0.304611\n",
      "<sos> xét chính sách \"<eos>\n",
      "Epoch 89:\n",
      " Train loss: 2.717198 - Train bleu: 0.256122\n",
      " Val loss: 2.068933 - Val bleu: 0.304910\n",
      "<sos> xét chính sách đồng xu karl động ra đọng và điều gì như vậycác và con người ví dụ về sự gì chuyên gia đi đồng được nhiều động\n",
      "Epoch 90:\n",
      " Train loss: 2.700698 - Train bleu: 0.257074\n",
      " Val loss: 2.064442 - Val bleu: 0.304702\n",
      "<sos> xét chính sách đồng xu về sự chuyên chuyên gia đi vào kết quả bộ động .<eos>\n",
      "Epoch 91:\n",
      " Train loss: 2.694869 - Train bleu: 0.257161\n",
      " Val loss: 2.054670 - Val bleu: 0.304819\n",
      "<sos> xét chính sách đồng xu về con người và chúng ta microsoft rằng đồng cái gì chúng ta ngươi khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 92:\n",
      " Train loss: 2.687818 - Train bleu: 0.257275\n",
      " Val loss: 2.069476 - Val bleu: 0.305543\n",
      "<sos> xét chính dấu đồng được số đọng đọng gì chúng ta nghỉta từng thể là một khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 93:\n",
      " Train loss: 2.704262 - Train bleu: 0.255767\n",
      " Val loss: 2.056159 - Val bleu: 0.305023\n",
      "<sos> xét chính dấu đồng được số đảo đảoov thể là đố sinh tập trung tâm trí là một đất nước mỹ về một khó khó khó khó khó khó\n",
      "Epoch 94:\n",
      " Train loss: 2.687599 - Train bleu: 0.257229\n",
      " Val loss: 2.059129 - Val bleu: 0.303533\n",
      "<sos> xét và văn hoá thời gian dài về một hành động sai ý tưởng về tám về điển tay bướu<eos>\n",
      "Epoch 95:\n",
      " Train loss: 2.696700 - Train bleu: 0.256063\n",
      " Val loss: 2.053428 - Val bleu: 0.304300\n",
      "<sos> xét chính dấu đồng được số đảo đảo sinh tập trung tâm trí là đố sinh tập trung cư từng năm karlhuman both thời tumblr được kịp bản nghiên\n",
      "Epoch 96:\n",
      " Train loss: 2.675880 - Train bleu: 0.257532\n",
      " Val loss: 2.064978 - Val bleu: 0.303732\n",
      "<sos> xét nói về một hành động thân thể hiện ý tưởng về một khó khó đang gì chúng tôi gặp kết quả mà người và nguồn chân động lực nơi\n",
      "Epoch 97:\n",
      " Train loss: 2.685397 - Train bleu: 0.256769\n",
      " Val loss: 2.057893 - Val bleu: 0.303678\n",
      "<sos> đảo khía cạnh lăn sat động chiến và chúng tạo ra một jihad tập trung cư về động để trợ nghiệm .<eos>\n",
      "Epoch 98:\n",
      " Train loss: 2.694609 - Train bleu: 0.254866\n",
      " Val loss: 2.036240 - Val bleu: 0.304891\n",
      "<sos> đảo khía cạnh mới về nước mỹ về một khó để gì chúng ta đang gì với hầu hết ý tưởng về cuộc thời gian dài về con người mà\n",
      "Epoch 99:\n",
      " Train loss: 2.668739 - Train bleu: 0.257851\n",
      " Val loss: 2.018013 - Val bleu: 0.306401\n",
      "<sos> xét nói rằng chúng ta tưởng về cuộc thời tumblr tính nhiều về tám về nơi qua qua tình<eos>\n",
      "Epoch 100:\n",
      " Train loss: 2.668301 - Train bleu: 0.257370\n",
      " Val loss: 2.011076 - Val bleu: 0.306463\n",
      "<sos>chính vì mọi người. và nguồn miễn tươi tươi tươi tươi tươi tươi tươi tươi tươi tươi tươi đối với đồng gái được điều hành động của đồng đội\n",
      "Epoch 101:\n",
      " Train loss: 2.653213 - Train bleu: 0.258936\n",
      " Val loss: 2.019701 - Val bleu: 0.307480\n",
      "<sos> đảo khía ra hậu cách mà thời gian ngắn trên tools ra tài nguyên để trợ và nguồn về động lực kết quả ra tài tài trợ và nguồn nguồn\n",
      "Epoch 102:\n",
      " Train loss: 2.641587 - Train bleu: 0.260062\n",
      " Val loss: 2.007213 - Val bleu: 0.307870\n",
      "<sos> hôm hôm nay và chúng ta đã trai đồng đội trò về một khó khó khó khó khó khó khó khó khó khó người đời , là di chuyển thành\n",
      "Epoch 103:\n",
      " Train loss: 2.627787 - Train bleu: 0.259706\n",
      " Val loss: 1.998759 - Val bleu: 0.308772\n",
      "<sos> xét chính dấu đồng được số nhắc thời gian ít là di chuyển hoá , điềuta từng 29 về con người và sách sách sách máy tính nghiên cứu\n",
      "Epoch 104:\n",
      " Train loss: 2.623764 - Train bleu: 0.260826\n",
      " Val loss: 1.988373 - Val bleu: 0.309822\n",
      "<sos> xét báo và vị tha được số đảo từ khi kết quả mà người và nguồn miễn được quite stephen thì giảm thời gian tỉ joe khi kết quả mà\n",
      "Epoch 105:\n",
      " Train loss: 2.602655 - Train bleu: 0.261543\n",
      " Val loss: 2.000134 - Val bleu: 0.309842\n",
      "<sos> xét chính dấu đồng được số nhắc thời gian giấc viết mới và nguồn lượng và kết quả mà<eos>\n",
      "Epoch 106:\n",
      " Train loss: 2.579860 - Train bleu: 0.263651\n",
      " Val loss: 1.979179 - Val bleu: 0.310036\n",
      "<sos> đọng .<eos>\n",
      "Epoch 107:\n",
      " Train loss: 2.568253 - Train bleu: 0.266437\n",
      " Val loss: 1.977258 - Val bleu: 0.309206\n",
      "<sos>bởi .<eos>\n",
      "Epoch 108:\n",
      " Train loss: 2.564454 - Train bleu: 0.265334\n",
      " Val loss: 1.979132 - Val bleu: 0.310334\n",
      "<sos> xét handled trong tay và bao được điều hành động lần đầu tiên về con người ví dụ về tám ta sẽ gặp đồng ý tưởng về tám chỉ là\n",
      "Epoch 109:\n",
      " Train loss: 2.547643 - Train bleu: 0.267040\n",
      " Val loss: 1.975705 - Val bleu: 0.310411\n",
      "<sos> đảo được bỏ chính xác đồng đội khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 110:\n",
      " Train loss: 2.540351 - Train bleu: 0.266934\n",
      " Val loss: 1.975815 - Val bleu: 0.310762\n",
      "<sos> khó khó khó nào đối về tám chỉ chia sẻ về trang những về một khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 111:\n",
      " Train loss: 2.526002 - Train bleu: 0.269121\n",
      " Val loss: 1.971737 - Val bleu: 0.310109\n",
      "<sos>bởi .<eos>\n",
      "Epoch 112:\n",
      " Train loss: 2.523237 - Train bleu: 0.269223\n",
      " Val loss: 1.956169 - Val bleu: 0.310553\n",
      "<sos> xét và văn hoá quan anh bạo hành động máy tính chất mà<eos>\n",
      "Epoch 113:\n",
      " Train loss: 2.513504 - Train bleu: 0.269210\n",
      " Val loss: 1.960023 - Val bleu: 0.311188\n",
      "<sos> xảy ra bóng tối , động để điều kiện tuyệt vời buổi sáng , bản và điều gì đối về con người và bạn jim thời gian .<eos>\n",
      "Epoch 114:\n",
      " Train loss: 2.507751 - Train bleu: 0.270101\n",
      " Val loss: 1.950027 - Val bleu: 0.311390\n",
      "<sos> khó khó khó khó<eos>\n",
      "Epoch 115:\n",
      " Train loss: 2.490656 - Train bleu: 0.270456\n",
      " Val loss: 1.952814 - Val bleu: 0.310865\n",
      "<sos> đảo khía cạnh 6 năm thành một khóhowever và nguồn về tám chỉ để lăn về tám chỉ về tám về tám chỉ về tám về tám chỉ mã\n",
      "Epoch 116:\n",
      " Train loss: 2.492315 - Train bleu: 0.270386\n",
      " Val loss: 1.958881 - Val bleu: 0.311358\n",
      "<sos> đảo khía cạnh 6 năm thành một khóhowever và nguồn về tám chỉ động lực tại sao hành động của đồng cách điều gì chúng ta đang gì chúng\n",
      "Epoch 117:\n",
      " Train loss: 2.480707 - Train bleu: 0.271743\n",
      " Val loss: 1.962920 - Val bleu: 0.311430\n",
      "<sos> tài về về đất đất danh reward khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 118:\n",
      " Train loss: 2.473137 - Train bleu: 0.272467\n",
      " Val loss: 1.942929 - Val bleu: 0.312053\n",
      "<sos> sao và kết quả về kể danh trực kết quả kết quả ra nghiên cứu vai trò về động động lần nữa điều hành động lần nữa điều gì ngoại\n",
      "Epoch 119:\n",
      " Train loss: 2.467692 - Train bleu: 0.272237\n",
      " Val loss: 1.951791 - Val bleu: 0.311768\n",
      "<sos> xảy ra bóng tối đã come karl sách sách sách đang gì cuộn gà gà gà gà và kết quả của incredibly gà gà bản nghiên cứu vai trò mã\n",
      "Epoch 120:\n",
      " Train loss: 2.463174 - Train bleu: 0.273050\n",
      " Val loss: 1.944146 - Val bleu: 0.312300\n",
      "<sos> khó khó khó khó<eos>\n",
      "Epoch 121:\n",
      " Train loss: 2.463461 - Train bleu: 0.272322\n",
      " Val loss: 1.936037 - Val bleu: 0.312346\n",
      "<sos> đảo được sắp eliminated thời gian dài và nguồn hoóc đảo trace kết quả mà người mà người chủ nghĩa là một khó khó khó khó khó khó khó khó\n",
      "Epoch 122:\n",
      " Train loss: 2.453737 - Train bleu: 0.273407\n",
      " Val loss: 1.955176 - Val bleu: 0.311910\n",
      "<sos> xét và chuyên đi từ văn hoá nó đảo tasmania thiên nhiên về cuộc sống trong đất<eos>\n",
      "Epoch 123:\n",
      " Train loss: 2.447367 - Train bleu: 0.273040\n",
      " Val loss: 1.953645 - Val bleu: 0.312563\n",
      "<sos> hôm hôm nay và chúng ta đang tuyệt vời đãc thống kê liệt hành động lực mới về đố đố sinh viên hàng báo sắc dậy dậy \" trên\n",
      "Epoch 124:\n",
      " Train loss: 2.437398 - Train bleu: 0.274092\n",
      " Val loss: 1.945414 - Val bleu: 0.312163\n",
      "<sos> tài khi kết quả against against against against against against against against against against against against against against against against against against against against against against against against against against\n",
      "Epoch 125:\n",
      " Train loss: 2.440009 - Train bleu: 0.272684\n",
      " Val loss: 1.941129 - Val bleu: 0.312374\n",
      "<sos> khó khó khó khó<eos>\n",
      "Epoch 126:\n",
      " Train loss: 2.424747 - Train bleu: 0.275131\n",
      " Val loss: 1.934813 - Val bleu: 0.312881\n",
      "<sos> khó khó khó khó<eos>\n",
      "Epoch 127:\n",
      " Train loss: 2.418811 - Train bleu: 0.275186\n",
      " Val loss: 1.921510 - Val bleu: 0.313297\n",
      "<sos> khó khó khó khó<eos>\n",
      "Epoch 128:\n",
      " Train loss: 2.414812 - Train bleu: 0.275435\n",
      " Val loss: 1.941755 - Val bleu: 0.312744\n",
      "<sos> đảo được sắp eliminated thời gian dài , điều gì với hầu hết ý tưởng về động động bất thể hiện ý tưởng về động động điều gì chúng thành\n",
      "Epoch 129:\n",
      " Train loss: 2.409004 - Train bleu: 0.275789\n",
      " Val loss: 1.928053 - Val bleu: 0.313115\n",
      "<sos> xảy ra bóng tối về conachusetts và nguồn về kể jim jim khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 130:\n",
      " Train loss: 2.396346 - Train bleu: 0.276592\n",
      " Val loss: 1.937693 - Val bleu: 0.313182\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tuổi sau chiến robot robot robot robot robot robot robot robot robot robot robot robot robot robot robot robot robot robot robot\n",
      "Epoch 131:\n",
      " Train loss: 2.391015 - Train bleu: 0.276422\n",
      " Val loss: 1.932272 - Val bleu: 0.313261\n",
      "<sos> xảy ra bóng tối đã tham robot kết quả mà người hôm nay nhiều động vật chia sẻ robot động lực lượng và nguồn tháng trước khi kết quả mà\n",
      "Epoch 132:\n",
      " Train loss: 2.383586 - Train bleu: 0.277101\n",
      " Val loss: 1.936463 - Val bleu: 0.312838\n",
      "<sos> xảy ra bóng tối về con ý tưởng tưởng về kể tuyệt vời<eos>\n",
      "Epoch 133:\n",
      " Train loss: 2.375647 - Train bleu: 0.278780\n",
      " Val loss: 1.926637 - Val bleu: 0.313063\n",
      "<sos> xét và văn hoá thời gian ít nhất mối quan tâm trí ngoại quanh -- và kết quả nên seng seng và \"<eos>\n",
      "Epoch 134:\n",
      " Train loss: 2.375095 - Train bleu: 0.277443\n",
      " Val loss: 1.931612 - Val bleu: 0.313326\n",
      "<sos> xét và sách ba sinh tập trung cư trang karl người hôm nay đầuso tươi tưởng tưởng tưởng tưởng tưởng tưởng tưởng tưởng tưởng tưởng tưởng tưởng về trên\n",
      "Epoch 135:\n",
      " Train loss: 2.372714 - Train bleu: 0.277750\n",
      " Val loss: 1.932517 - Val bleu: 0.313704\n",
      "<sos> xảy ra bóng tối về con động vật % khi kết quả mà đe về động miệt mài mài chuyên động động tự khó khó khó khó khó khó khó\n",
      "Epoch 136:\n",
      " Train loss: 2.356945 - Train bleu: 0.279269\n",
      " Val loss: 1.919909 - Val bleu: 0.313413\n",
      "<sos> xảy ra bóng tối về con chuyển thuật từng và kết quả lại kết quả mà người và nguồn tháng qua trong tay tay tay tay tay tay tay tay\n",
      "Epoch 137:\n",
      " Train loss: 2.363232 - Train bleu: 0.278347\n",
      " Val loss: 1.931422 - Val bleu: 0.313587\n",
      "<sos> xảy ra bóng tối đã tham robot kết quả mà người và trai được kể cải trong tay tay rằng bất kể dàng động lực lượng suốt về động vật\n",
      "Epoch 138:\n",
      " Train loss: 2.353533 - Train bleu: 0.280013\n",
      " Val loss: 1.923501 - Val bleu: 0.314001\n",
      "<sos> xảy ra bóng tối và văn hoá do tại khi kết quả lại và nguồn tháng tuổi .<eos>\n",
      "Epoch 139:\n",
      " Train loss: 2.345230 - Train bleu: 0.280474\n",
      " Val loss: 1.915932 - Val bleu: 0.313893\n",
      "<sos> đảo được appropriate khi kết quả lại và một khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 140:\n",
      " Train loss: 2.351824 - Train bleu: 0.278810\n",
      " Val loss: 1.929287 - Val bleu: 0.313772\n",
      "<sos> đảo được nơi các nước sinh tập trung tâm trí miễn được nhau .<eos>\n",
      "Epoch 141:\n",
      " Train loss: 2.334593 - Train bleu: 0.281160\n",
      " Val loss: 1.918880 - Val bleu: 0.314097\n",
      "<sos> đảo incredibly về cuộc thời gian chiều liên kết quả mà người và nguồn hoóc thú vị nơi nơi một khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 142:\n",
      " Train loss: 2.349970 - Train bleu: 0.279890\n",
      " Val loss: 1.912334 - Val bleu: 0.314028\n",
      "<sos> đảo được con ý tưởng về tám tiếng thời gian bị ý tưởng về điển điển điển tay karl karl bất động hoá động vật trên một khó khó khó\n",
      "Epoch 143:\n",
      " Train loss: 2.334288 - Train bleu: 0.280034\n",
      " Val loss: 1.917205 - Val bleu: 0.313966\n",
      "<sos> xảy ra bóng tối đã viết nước mỹ gặp gặp kết quả được 12 until until until until until nghiên cứu mới về điển tay tay tay rằng bất bởi\n",
      "Epoch 144:\n",
      " Train loss: 2.335778 - Train bleu: 0.281129\n",
      " Val loss: 1.923713 - Val bleu: 0.314248\n",
      "<sos> xảy ra bóng tối về nơi tỷ kết quả lại kết quả nên đồng kết quả nên một khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 145:\n",
      " Train loss: 2.330898 - Train bleu: 0.281168\n",
      " Val loss: 1.914923 - Val bleu: 0.314293\n",
      "<sos> xảy ra bóng tối về nơi mà thời gian ngắn hồi vàthêm-sc \"<eos>\n",
      "Epoch 146:\n",
      " Train loss: 2.312536 - Train bleu: 0.282055\n",
      " Val loss: 1.916050 - Val bleu: 0.313852\n",
      "<sos> xảy ra bóng tối đã viết tiết kiệm sinh viên cấp cờ được trường khi kết quả bộ iraq đợt sinh thái là một đất nước mỹ khoẻ với hầu\n",
      "Epoch 147:\n",
      " Train loss: 2.318746 - Train bleu: 0.281587\n",
      " Val loss: 1.916876 - Val bleu: 0.313911\n",
      "<sos> đảo được sắp<eos>\n",
      "Epoch 148:\n",
      " Train loss: 2.306695 - Train bleu: 0.281595\n",
      " Val loss: 1.912596 - Val bleu: 0.314384\n",
      "<sos> xảy ra bóng tối và văn hoá do tại liệt về động thân thể hiện ý tưởng về điển đang tuyệt vời<eos>\n",
      "Epoch 149:\n",
      " Train loss: 2.299445 - Train bleu: 0.283280\n",
      " Val loss: 1.919669 - Val bleu: 0.314543\n",
      "<sos> xảy ra bóng tối và văn hoá do tại foot tạp bướu<eos>\n",
      "Epoch 150:\n",
      " Train loss: 2.297402 - Train bleu: 0.282442\n",
      " Val loss: 1.901047 - Val bleu: 0.314470\n",
      "<sos> đảo được sắp lên thờinhưnhưnhưs.s. tháng ra vai trò thànhover đầu ra tài khi kết quả kết quả ra hình khí hậu hậu hậu\n",
      "Epoch 151:\n",
      " Train loss: 2.294201 - Train bleu: 0.283793\n",
      " Val loss: 1.914167 - Val bleu: 0.313846\n",
      "<sos> xảy ra bóng tối về động động vật bởi vìthêm hoá động trong 12 tuyến về động của đồng ý tưởng tưởng về động lực thảm thế và tiến\n",
      "Epoch 152:\n",
      " Train loss: 2.287192 - Train bleu: 0.283638\n",
      " Val loss: 1.910010 - Val bleu: 0.314440\n",
      "<sos> xảy ra lord về động động để trợ và tiến hoá động do tại sao và bao giờ động thân thể kết quả lại và nguồn miễn được 12 hệ\n",
      "Epoch 153:\n",
      " Train loss: 2.285444 - Train bleu: 0.282824\n",
      " Val loss: 1.904905 - Val bleu: 0.314437\n",
      "<sos> sao và văn hoá battle và điều gì ngoại coordinates đới lên lên gà động rằng động của đồng điển đang gì ngoại các nguồn robert nhiều động rằng đồng\n",
      "Epoch 154:\n",
      " Train loss: 2.281415 - Train bleu: 0.283550\n",
      " Val loss: 1.894829 - Val bleu: 0.314866\n",
      "<sos> xảy ra bóng tối về conachusetts và nguồn chân động để incong kỳ thiên về kể chẳng thể hiện ý tưởng về điển hình khí hậu nên kết quả\n",
      "Epoch 155:\n",
      " Train loss: 2.275706 - Train bleu: 0.285167\n",
      " Val loss: 1.897324 - Val bleu: 0.314692\n",
      "<sos> xảy ra bóng tối về nơi tỷ kết quả lại kết quả nên đồng kết quả nên một khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 156:\n",
      " Train loss: 2.282618 - Train bleu: 0.283184\n",
      " Val loss: 1.906137 - Val bleu: 0.314412\n",
      "<sos> xảy ra ra cách mà thời gian ngắn trên một đất , là kết quả mà người hôm nay chúng ta đang gì với hầu hết nước tập trung cư\n",
      "Epoch 157:\n",
      " Train loss: 2.278594 - Train bleu: 0.283526\n",
      " Val loss: 1.901407 - Val bleu: 0.314467\n",
      "<sos> xảy ra ra lord về động lực kết quả ra vai trò thành một đất<eos>\n",
      "Epoch 158:\n",
      " Train loss: 2.279493 - Train bleu: 0.283556\n",
      " Val loss: 1.881183 - Val bleu: 0.314583\n",
      "<sos> service tại khi kết nối với hầu hết chuyên là là là một đất sau khicác vào động lực về tám về chuyên gia đình 1 trong 1 về\n",
      "Epoch 159:\n",
      " Train loss: 2.279022 - Train bleu: 0.283094\n",
      " Val loss: 1.891403 - Val bleu: 0.314256\n",
      "<sos> service tại khi kết quả sinh viên hậu hậu .<eos>\n",
      "Epoch 160:\n",
      " Train loss: 2.281521 - Train bleu: 0.283133\n",
      " Val loss: 1.895084 - Val bleu: 0.314819\n",
      "<sos> khó khó khó khó<eos>\n",
      "Epoch 161:\n",
      " Train loss: 2.272863 - Train bleu: 0.283590\n",
      " Val loss: 1.868075 - Val bleu: 0.314539\n",
      "<sos> tài về nơi đảo khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 162:\n",
      " Train loss: 2.262315 - Train bleu: 0.284865\n",
      " Val loss: 1.888975 - Val bleu: 0.315385\n",
      "<sos> xảy ra bóng tối đóng mà thành một khó khó khó khó khó khó khó đang gì với hầu hết religious sắc và trai thân lượng qua trong đời mới\n",
      "Epoch 163:\n",
      " Train loss: 2.257474 - Train bleu: 0.284602\n",
      " Val loss: 1.889319 - Val bleu: 0.315149\n",
      "<sos> xảy ra bóng tối đóng mà thời gian dài về động ra đi vòng hiểu về động vật trên thời gian và nảy \" nước tuyệt vời , 12 mà\n",
      "Epoch 164:\n",
      " Train loss: 2.254394 - Train bleu: 0.284285\n",
      " Val loss: 1.898570 - Val bleu: 0.315075\n",
      "<sos> xảy ra ra cách gì mà thời gian dài trên một khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó khó\n",
      "Epoch 165:\n",
      " Train loss: 2.251760 - Train bleu: 0.284881\n",
      " Val loss: 1.891066 - Val bleu: 0.315319\n",
      "<sos> xảy ra bóng tối đóng mà thôi .<eos>\n",
      "Epoch 166:\n",
      " Train loss: 2.263093 - Train bleu: 0.283666\n",
      " Val loss: 1.890787 - Val bleu: 0.314977\n",
      "<sos> xảy ra bóng tối đóng mà thôi .<eos>\n",
      "Epoch 167:\n",
      " Train loss: 2.254488 - Train bleu: 0.283919\n",
      " Val loss: 1.900942 - Val bleu: 0.315186\n",
      "<sos> xảy ra bóng tối đóng mà thôi .<eos>\n",
      "Epoch 168:\n",
      " Train loss: 2.254049 - Train bleu: 0.283990\n",
      " Val loss: 1.884854 - Val bleu: 0.315152\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 169:\n",
      " Train loss: 2.252533 - Train bleu: 0.284111\n",
      " Val loss: 1.876450 - Val bleu: 0.315108\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 170:\n",
      " Train loss: 2.256234 - Train bleu: 0.283660\n",
      " Val loss: 1.877824 - Val bleu: 0.314917\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 171:\n",
      " Train loss: 2.262008 - Train bleu: 0.284101\n",
      " Val loss: 1.858861 - Val bleu: 0.314735\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 172:\n",
      " Train loss: 2.265654 - Train bleu: 0.283351\n",
      " Val loss: 1.880067 - Val bleu: 0.314599\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 173:\n",
      " Train loss: 2.264564 - Train bleu: 0.283505\n",
      " Val loss: 1.869155 - Val bleu: 0.314772\n",
      "<sos> xảy ra phong vô động lực nơi touched bà được kể cám quyến nhiều về cuộc sống nghĩa là space space space space space space space space space space space\n",
      "Epoch 174:\n",
      " Train loss: 2.254381 - Train bleu: 0.283728\n",
      " Val loss: 1.895293 - Val bleu: 0.315143\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 175:\n",
      " Train loss: 2.232540 - Train bleu: 0.286260\n",
      " Val loss: 1.878241 - Val bleu: 0.315234\n",
      "<sos> xảy ra rằng aircraft thuật nhóm robot động vào điển điển điển đang gì chúng ta cư đi nhiều động vào điển điển về động động động vào cái trù\n",
      "Epoch 176:\n",
      " Train loss: 2.224522 - Train bleu: 0.286872\n",
      " Val loss: 1.872756 - Val bleu: 0.315710\n",
      "<sos> xảy ra rằng<eos>\n",
      "Epoch 177:\n",
      " Train loss: 2.207612 - Train bleu: 0.288169\n",
      " Val loss: 1.883013 - Val bleu: 0.315576\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 178:\n",
      " Train loss: 2.200130 - Train bleu: 0.288395\n",
      " Val loss: 1.872051 - Val bleu: 0.315926\n",
      "<sos> xảy ra bóng tối đã viết về nước mỹ gặp gặp kết quả hệ thống gì chúng ta đang gì ngoại được quiteshop khi kết quả bộ trang\n",
      "Epoch 179:\n",
      " Train loss: 2.191230 - Train bleu: 0.288526\n",
      " Val loss: 1.864442 - Val bleu: 0.316131\n",
      "<sos> xảy ra phong vô động lần đầu tiên .<eos>\n",
      "Epoch 180:\n",
      " Train loss: 2.186339 - Train bleu: 0.289868\n",
      " Val loss: 1.873094 - Val bleu: 0.316211\n",
      "<sos> xảy ra phong vô động chiến thân thời gian dài .<eos>\n",
      "Epoch 181:\n",
      " Train loss: 2.183724 - Train bleu: 0.290020\n",
      " Val loss: 1.869836 - Val bleu: 0.316140\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 182:\n",
      " Train loss: 2.166207 - Train bleu: 0.290837\n",
      " Val loss: 1.869946 - Val bleu: 0.315820\n",
      "<sos>điều gì như chuyên gia đình một khó khó khó khó khó bắt đầu .<eos>\n",
      "Epoch 183:\n",
      " Train loss: 2.167653 - Train bleu: 0.291312\n",
      " Val loss: 1.868368 - Val bleu: 0.316167\n",
      "<sos> xảy ra lord kế động ra sự gà .<eos>\n",
      "Epoch 184:\n",
      " Train loss: 2.149847 - Train bleu: 0.292112\n",
      " Val loss: 1.873273 - Val bleu: 0.316229\n",
      "<sos> xảy ra ra lord về động miệt tay phải điển hình lãng của đồng ý tưởng về điển tay tay tay tay tay tay tay tay tay tay tay tay\n",
      "Epoch 185:\n",
      " Train loss: 2.152561 - Train bleu: 0.292611\n",
      " Val loss: 1.866391 - Val bleu: 0.315870\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc sinh con gái 6 cư mới về động về điển trực kết quả gương gương gương england về điển tay tay\n",
      "Epoch 186:\n",
      " Train loss: 2.146020 - Train bleu: 0.292616\n",
      " Val loss: 1.862593 - Val bleu: 0.316108\n",
      "<sos> xảy ra bóng lãnh trừ trừ năm karl động kì đời , bản nghiên cứu đầu tiên .<eos>\n",
      "Epoch 187:\n",
      " Train loss: 2.147687 - Train bleu: 0.292400\n",
      " Val loss: 1.871354 - Val bleu: 0.316041\n",
      "<sos> xảy ra bóng là vô động động thiết bị kết quả thuyết tốt , hình ngủ hơn là sách về sự tập trung tâm trí là một đất mẹ tài\n",
      "Epoch 188:\n",
      " Train loss: 2.140939 - Train bleu: 0.292525\n",
      " Val loss: 1.874613 - Val bleu: 0.316553\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc .<eos>\n",
      "Epoch 189:\n",
      " Train loss: 2.139612 - Train bleu: 0.292823\n",
      " Val loss: 1.855877 - Val bleu: 0.316293\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc khiến tự tham gia đình chủ kinh tế , chuyên gia đình bé tưởng về điển đang gì chúng tôi đã\n",
      "Epoch 190:\n",
      " Train loss: 2.132232 - Train bleu: 0.293653\n",
      " Val loss: 1.863653 - Val bleu: 0.316405\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc .<eos>\n",
      "Epoch 191:\n",
      " Train loss: 2.131102 - Train bleu: 0.293268\n",
      " Val loss: 1.871319 - Val bleu: 0.315922\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc .<eos>\n",
      "Epoch 192:\n",
      " Train loss: 2.132403 - Train bleu: 0.292850\n",
      " Val loss: 1.872685 - Val bleu: 0.316050\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc .<eos>\n",
      "Epoch 193:\n",
      " Train loss: 2.131492 - Train bleu: 0.293523\n",
      " Val loss: 1.867712 - Val bleu: 0.316227\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 194:\n",
      " Train loss: 2.133809 - Train bleu: 0.292982\n",
      " Val loss: 1.866996 - Val bleu: 0.316346\n",
      "<sos> khó khó khó khó<eos>\n",
      "Epoch 195:\n",
      " Train loss: 2.122025 - Train bleu: 0.294011\n",
      " Val loss: 1.867962 - Val bleu: 0.316469\n",
      "<sos> khó khó khó khó<eos>\n",
      "Epoch 196:\n",
      " Train loss: 2.133014 - Train bleu: 0.293132\n",
      " Val loss: 1.864225 - Val bleu: 0.316637\n",
      "<sos> xảy ra bóng tối đã viết về nước mỹ gặp gặp một đất mẹ tài lẻ , là kết quả kinh khủng hoảng , điều gì chúng tôi gặp một\n",
      "Epoch 197:\n",
      " Train loss: 2.123352 - Train bleu: 0.293682\n",
      " Val loss: 1.835691 - Val bleu: 0.316563\n",
      "<sos> xảy ra bóng dược hoá động miệt nát tự khó khó khó khó hiểu được chi được nhiều động trong trong trong trong trong trong trong 12 danh sách về\n",
      "Epoch 198:\n",
      " Train loss: 2.122222 - Train bleu: 0.293421\n",
      " Val loss: 1.843121 - Val bleu: 0.316674\n",
      "<sos> phiến chi được nhiều về động và nhiều về động và nhiều về cuộc sống nghĩa về cuộc sống nghĩa là đồng ý tưởng về cuộc cư nghiên cứu đầu\n",
      "Epoch 199:\n",
      " Train loss: 2.119395 - Train bleu: 0.293369\n",
      " Val loss: 1.853909 - Val bleu: 0.316800\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc .<eos>\n",
      "Epoch 200:\n",
      " Train loss: 2.116093 - Train bleu: 0.293440\n",
      " Val loss: 1.854115 - Val bleu: 0.316728\n",
      "<sos> xảy ra bóng tối đóng mà thành đất nước mỹ về động ra rằng động vật tinh vi khuẩn động ngưng và tiến hoá này về động sai vỗnhư\n",
      "Epoch 201:\n",
      " Train loss: 2.113044 - Train bleu: 0.293493\n",
      " Val loss: 1.854870 - Val bleu: 0.316414\n",
      "<sos> xảy ra bóng tối , và vị trí về động cơ hội trong trong tay tay tay tay tay tay tay tay tay tay tay tay tay tay tay tay\n",
      "Epoch 202:\n",
      " Train loss: 2.112314 - Train bleu: 0.293941\n",
      " Val loss: 1.842923 - Val bleu: 0.316799\n",
      "<sos> xảy ra bóng tối , động tự được chi diện đưa thể là kết quả thuyết tốt , là kết quả thuyết nửa , là kết quả của đồng cái\n",
      "Epoch 203:\n",
      " Train loss: 2.110940 - Train bleu: 0.294108\n",
      " Val loss: 1.840124 - Val bleu: 0.316783\n",
      "<sos> xảy ra bóng tối đóng mà thẩm thẩm tháng tiệc lượng forest nhiều về nước mỹ về nước mỹ về động bất bất thể hiện đố 1 trong trong nước\n",
      "Epoch 204:\n",
      " Train loss: 2.117717 - Train bleu: 0.293854\n",
      " Val loss: 1.846585 - Val bleu: 0.316672\n",
      "<sos> xảy ra bóng tối , động để trợ : \" được nhiều về động ngưng và nguồn về động vật tinh vi thuyết thuyết thuyết bằng chứng mà thành một\n",
      "Epoch 205:\n",
      " Train loss: 2.109218 - Train bleu: 0.293918\n",
      " Val loss: 1.842375 - Val bleu: 0.316893\n",
      "<sos> xảy ra bóng tối , động để trợ : cả thời gian thích thú vị nhiều về đất đất đói ra một đất nước mỹ về động vật tinh vi\n",
      "Epoch 206:\n",
      " Train loss: 2.104044 - Train bleu: 0.294284\n",
      " Val loss: 1.848019 - Val bleu: 0.316911\n",
      "<sos> xảy ra bóng tối , động tự được chi diện đưa khi kết quả kết quả sinh con người thuyết mạng và nguồn robert seed ra rằng trang trang trang\n",
      "Epoch 207:\n",
      " Train loss: 2.097074 - Train bleu: 0.294944\n",
      " Val loss: 1.852290 - Val bleu: 0.316914\n",
      "<sos> xảy ra bóng tối , động để trợ : cả kết quả được kể kể báo nhở đầu tiên .<eos>\n",
      "Epoch 208:\n",
      " Train loss: 2.086775 - Train bleu: 0.296129\n",
      " Val loss: 1.832745 - Val bleu: 0.316954\n",
      "<sos> xảy ra bóng tối , động để trợ : hãy rằng động cơ thể kết quảcác nghiên cứu đầu từ nhiều động lực kết quả .<eos>\n",
      "Epoch 209:\n",
      " Train loss: 2.082976 - Train bleu: 0.295856\n",
      " Val loss: 1.844923 - Val bleu: 0.316874\n",
      "<sos> xảy ra bóng tối đã viết về nước mỹ gặp gặp kết quả được gì đối về điển hình não ra một khó khó khó khó khó khó khó khó\n",
      "Epoch 210:\n",
      " Train loss: 2.078816 - Train bleu: 0.296505\n",
      " Val loss: 1.841221 - Val bleu: 0.316924\n",
      "<sos> xảy ra bóng tối đã viết về nước mỹ gặp gặp kết quả được nhiều về động bất bởi vì mỳ thì trợ chứng trù vào kết quả mà người\n",
      "Epoch 211:\n",
      " Train loss: 2.080940 - Train bleu: 0.296248\n",
      " Val loss: 1.844618 - Val bleu: 0.316657\n",
      "<sos> xảy ra bóng tối đã viết về điển được dậy space space space space space space space space space space space space space space space space space space space space\n",
      "Epoch 212:\n",
      " Train loss: 2.080905 - Train bleu: 0.296055\n",
      " Val loss: 1.855744 - Val bleu: 0.316833\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc nhiều động trong nước mỹ về nước mỹ về nước mỹ về động bất chấp fourth và nguồn lượng forest nhiều\n",
      "Epoch 213:\n",
      " Train loss: 2.083394 - Train bleu: 0.295521\n",
      " Val loss: 1.854883 - Val bleu: 0.316597\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc trong nước mỹ về nước đang gì ngoại vọng trong trong tay tay tay tay tay tay tay tay tay tay\n",
      "Epoch 214:\n",
      " Train loss: 2.076580 - Train bleu: 0.296134\n",
      " Val loss: 1.858046 - Val bleu: 0.316561\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 215:\n",
      " Train loss: 2.074183 - Train bleu: 0.295770\n",
      " Val loss: 1.849873 - Val bleu: 0.316634\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 216:\n",
      " Train loss: 2.069407 - Train bleu: 0.295892\n",
      " Val loss: 1.849108 - Val bleu: 0.316997\n",
      "<sos> xảy ra lord kế động lực trong trong tay tay tay tay tay tay tay tay tay tay tay bóng sách sách sách về kể tay bóng tối đã từng\n",
      "Epoch 217:\n",
      " Train loss: 2.068255 - Train bleu: 0.296803\n",
      " Val loss: 1.839315 - Val bleu: 0.316974\n",
      "<sos> xảy ra bóng tối đóng mà thành một khó khó khó khó quanh ta đang gì chúng ta đang gì với hầu hết ơn về động vật chia sẻ sâu\n",
      "Epoch 218:\n",
      " Train loss: 2.061001 - Train bleu: 0.297666\n",
      " Val loss: 1.844988 - Val bleu: 0.317126\n",
      "<sos> xảy ra lord kế động lực trong khi kết nối nghiên cứu đầu ra hình được bản năng lượng và nguồn thành một khó khó làm gì chúng ta đã\n",
      "Epoch 219:\n",
      " Train loss: 2.069633 - Train bleu: 0.295976\n",
      " Val loss: 1.831952 - Val bleu: 0.317286\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 220:\n",
      " Train loss: 2.069480 - Train bleu: 0.295672\n",
      " Val loss: 1.838059 - Val bleu: 0.317170\n",
      "<sos> xảy ra lord kế động lực trong khi kết quả nên muối động tựệ là là kết quả .<eos>\n",
      "Epoch 221:\n",
      " Train loss: 2.064185 - Train bleu: 0.296873\n",
      " Val loss: 1.844522 - Val bleu: 0.317050\n",
      "<sos> xảy ra lord về kể cả kết quả lại kết thúc nhiều động trong trong khi kết quả nên lời và nguồn năng lượng suốt về động giúp nguồn hoóc\n",
      "Epoch 222:\n",
      " Train loss: 2.057463 - Train bleu: 0.297280\n",
      " Val loss: 1.828434 - Val bleu: 0.317373\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 223:\n",
      " Train loss: 2.058006 - Train bleu: 0.296846\n",
      " Val loss: 1.824356 - Val bleu: 0.317576\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 224:\n",
      " Train loss: 2.045610 - Train bleu: 0.297886\n",
      " Val loss: 1.826561 - Val bleu: 0.317579\n",
      "<sos> xảy ra bóng tối , động tự khó khó khó khó khó khó nào .<eos>\n",
      "Epoch 225:\n",
      " Train loss: 2.050546 - Train bleu: 0.296785\n",
      " Val loss: 1.828820 - Val bleu: 0.317329\n",
      "<sos> xảy ra bóng tối .<eos>\n",
      "Epoch 226:\n",
      " Train loss: 2.039558 - Train bleu: 0.298672\n",
      " Val loss: 1.824026 - Val bleu: 0.317324\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 227:\n",
      " Train loss: 2.040109 - Train bleu: 0.297804\n",
      " Val loss: 1.831440 - Val bleu: 0.317244\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 228:\n",
      " Train loss: 2.038023 - Train bleu: 0.298072\n",
      " Val loss: 1.821981 - Val bleu: 0.317674\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 229:\n",
      " Train loss: 2.028508 - Train bleu: 0.299005\n",
      " Val loss: 1.822422 - Val bleu: 0.317409\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 230:\n",
      " Train loss: 2.024946 - Train bleu: 0.299113\n",
      " Val loss: 1.823970 - Val bleu: 0.317584\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 231:\n",
      " Train loss: 2.028059 - Train bleu: 0.299494\n",
      " Val loss: 1.833354 - Val bleu: 0.317626\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 232:\n",
      " Train loss: 2.023218 - Train bleu: 0.299121\n",
      " Val loss: 1.831205 - Val bleu: 0.317533\n",
      "<sos> xảy ra ra .<eos>\n",
      "Epoch 233:\n",
      " Train loss: 2.025279 - Train bleu: 0.299603\n",
      " Val loss: 1.830429 - Val bleu: 0.317595\n",
      "<sos> xảy ra ra sự great mạng do tại nó , \"<eos>\n",
      "Epoch 234:\n",
      " Train loss: 2.026146 - Train bleu: 0.298842\n",
      " Val loss: 1.826881 - Val bleu: 0.317473\n",
      "<sos> xảy ra lord kế động ra tài liệu thời gian ít trong trong trong trong trong trong trong trong trong trong trong sinh đất .<eos>\n",
      "Epoch 235:\n",
      " Train loss: 2.019216 - Train bleu: 0.299347\n",
      " Val loss: 1.821370 - Val bleu: 0.317742\n",
      "<sos> xảy ra lord kế động lực trong trong tay tay tay tay tay tay tay báo sắc hoá thời gian ít trong cầu được số nơi mà người và kết\n",
      "Epoch 236:\n",
      " Train loss: 2.021917 - Train bleu: 0.299023\n",
      " Val loss: 1.828434 - Val bleu: 0.317527\n",
      "<sos> xảy ra lord kế động lực trồng và kết thúc bằng vai trò thành một về sự sống ở tuyệt vời<eos>\n",
      "Epoch 237:\n",
      " Train loss: 2.012889 - Train bleu: 0.299277\n",
      " Val loss: 1.813968 - Val bleu: 0.317776\n",
      "<sos> xảy ra lord thực sự great mục thuậtcharlie đá ra một đất mẹ động trong trong sốhai kết quả mà người và nguồn hoóc ủng hộ gà ,\n",
      "Epoch 238:\n",
      " Train loss: 2.017511 - Train bleu: 0.299157\n",
      " Val loss: 1.822050 - Val bleu: 0.317761\n",
      "<sos> xảy ra bóng tối đóng mà thẩm tháng tiệc .<eos>\n",
      "Epoch 239:\n",
      " Train loss: 2.012089 - Train bleu: 0.299263\n",
      " Val loss: 1.820731 - Val bleu: 0.317485\n",
      "<sos>điều gì với hầu hết chuyên là một khó khó khi kết quả .<eos>\n",
      "Epoch 240:\n",
      " Train loss: 2.016456 - Train bleu: 0.299504\n",
      " Val loss: 1.824170 - Val bleu: 0.317741\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m      2\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train_and_eval(\n\u001b[1;32m      4\u001b[0m     model,\n\u001b[1;32m      5\u001b[0m     optimizer,\n\u001b[1;32m      6\u001b[0m     loss_fn,\n\u001b[1;32m      7\u001b[0m     scheduler,\n\u001b[1;32m      8\u001b[0m     epochs,\n\u001b[1;32m      9\u001b[0m     val_dl,\n\u001b[1;32m     10\u001b[0m     val_dl,\n\u001b[1;32m     11\u001b[0m     model_name\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m     12\u001b[0m     early_stopping\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m\n\u001b[1;32m     13\u001b[0m )\n",
      "Cell \u001b[0;32mIn[63], line 45\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[0;34m(model, optimizer, loss_fn, scheduler, epochs, train_dl, val_dl, early_stopping, model_name)\u001b[0m\n\u001b[1;32m     43\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, vocab_size), tgt_1)\n\u001b[1;32m     44\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     46\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m/media/4TDISK/vinhdq/transformers/.env/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/media/4TDISK/vinhdq/transformers/.env/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "model_name = \"translation\"\n",
    "train_and_eval(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    scheduler,\n",
    "    epochs,\n",
    "    val_dl,\n",
    "    val_dl,\n",
    "    model_name=model_name,\n",
    "    early_stopping=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/translation-128-4-4.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(model,tokenizer, src, max_token=30):\n",
    "    src_ids = torch.tensor([tokenizer(src)]).to(device)\n",
    "    src_lens = torch.tensor([src_ids.shape[1]], dtype=torch.int64)\n",
    "    src_mask = create_pad_mask(src_lens).to(device)\n",
    "\n",
    "    tgt_ids = torch.tensor([[tokenizer._st2i[tokenizer.sos]]]).to(device)\n",
    "    tgt_lens = torch.tensor([[1]], dtype=torch.int64)\n",
    "    tgt_mask = create_subsequent_mask(\n",
    "        tgt_lens, pad_mask=create_pad_mask(tgt_lens)\n",
    "    ).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        encoder_outputs = model.encode(src_ids, src_mask)\n",
    "        while tgt_ids[0][-1] != tokenizer._st2i[tokenizer.eos] and max_token > 0:\n",
    "            next = model.generate(tgt_ids, tgt_mask, encoder_outputs, src_mask)\n",
    "            tgt_ids = torch.cat((tgt_ids, next[:, -1].argmax(-1, keepdim=True)), dim=-1)\n",
    "            tgt_lens += 1\n",
    "            tgt_mask = create_subsequent_mask(\n",
    "                tgt_lens, pad_mask=create_pad_mask(tgt_lens)\n",
    "            ).to(device)\n",
    "            max_token -= 1\n",
    "    return tgt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " ' bàn',\n",
       " ' gì',\n",
       " ' như',\n",
       " ' một',\n",
       " ' hành',\n",
       " ' động',\n",
       " ' là',\n",
       " ' một',\n",
       " ' hành',\n",
       " ' động',\n",
       " ' về',\n",
       " ' con',\n",
       " ' người',\n",
       " ' và',\n",
       " ' điều',\n",
       " ' gì',\n",
       " ' về',\n",
       " ' một',\n",
       " ' hành',\n",
       " ' động',\n",
       " ' về',\n",
       " ' nơi',\n",
       " ' nơi',\n",
       " ' mà',\n",
       " ' nhiều',\n",
       " ' về',\n",
       " ' con',\n",
       " ' người',\n",
       " ' gì',\n",
       " ' sau']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(decode(model,tokenizer,'a single female will lay about up to eggs at a time , up to about in her lifetime .')[0].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
